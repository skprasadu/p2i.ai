import fs from "node:fs";
import path from "node:path";
import crypto from "node:crypto";
import { execFileSync } from "node:child_process";
import matter from "gray-matter";

const ROOT = process.cwd();
const CONTENT_DIR = path.join(ROOT, "content");
const OUT_INDEX = path.join(ROOT, "src", "generated", "contentIndex.ts");
const OUT_CACHE_DIR = path.join(ROOT, ".content_cache");
const OUT_DIAGRAMS_DIR = path.join(ROOT, "public", "diagrams");

// Sections you want
const SECTIONS = ["research", "projects", "products", "notes"];

function ensureDir(p) {
  fs.mkdirSync(p, { recursive: true });
}

function readFilesRecursive(dir) {
  const out = [];
  for (const ent of fs.readdirSync(dir, { withFileTypes: true })) {
    const full = path.join(dir, ent.name);
    if (ent.isDirectory()) out.push(...readFilesRecursive(full));
    else out.push(full);
  }
  return out;
}

function sha1(s) {
  return crypto.createHash("sha1").update(s).digest("hex");
}

/**
 * Extract mermaid fences and replace with MDX component calls.
 * We output MermaidImage with src+alt+caption+code.
 */
function transformMermaidToImages({ mdx, title, description }) {
  const mermaidFence = /```mermaid\s*\n([\s\S]*?)\n```/g;
  let idx = 0;

  return mdx.replace(mermaidFence, (_m, code) => {
    idx += 1;
    const trimmed = String(code).trim();
    const hash = sha1(trimmed);
    const svgRel = `/diagrams/${hash}.svg`;
    const svgAbs = path.join(OUT_DIAGRAMS_DIR, `${hash}.svg`);

    // render SVG if missing
    if (!fs.existsSync(svgAbs)) {
      const tmpMmd = path.join(OUT_DIAGRAMS_DIR, `${hash}.mmd`);
      fs.writeFileSync(tmpMmd, trimmed, "utf8");

      // mermaid-cli: mmdc -i input -o output -b transparent
      // Use execFileSync so build fails loudly if mermaid fails.
      const mmdcBin = path.join(
        ROOT,
        "node_modules",
        ".bin",
        process.platform === "win32" ? "mmdc.cmd" : "mmdc"
      );

      execFileSync(
        mmdcBin,
        ["-i", tmpMmd, "-o", svgAbs, "-b", "transparent"],
        { stdio: "inherit" }
      );

      fs.unlinkSync(tmpMmd);
    }

    const alt = `${title} — architecture diagram ${idx}`;
    const caption = description ? String(description) : `${title} diagram`;

    // JSON.stringify makes it safe inside MDX props
    return [
      "",
      `<MermaidImage`,
      `  src=${JSON.stringify(svgRel)}`,
      `  alt=${JSON.stringify(alt)}`,
      `  caption=${JSON.stringify(caption)}`,
      `  code=${JSON.stringify(trimmed)}`,
      `/>`,
      ""
    ].join("\n");
  });
}

function normalizeFrontmatter(data, filePath) {
  // strict-but-friendly defaults
  const title = data.title ?? path.basename(filePath).replace(/\.(md|mdx)$/, "");
  const description = data.description ?? "";
  const date = data.date ?? null;
  const tags = Array.isArray(data.tags) ? data.tags : [];
  const repo = data.repo ?? null;
  const status = data.status ?? "published";

  return { title, description, date, tags, repo, status };
}

function slugFromPath(filePath) {
  const base = path.basename(filePath).replace(/\.(md|mdx)$/, "");
  // keep it simple and stable; you can later enforce kebab-case
  return base.toLowerCase().replace(/\s+/g, "-");
}

function writeIndex(items) {
  const content = `// AUTO-GENERATED by scripts/build-content.mjs. DO NOT EDIT.
export type ContentSection = "research" | "projects" | "products" | "notes";

export type ContentItem = {
  section: ContentSection;
  slug: string;
  title: string;
  description: string;
  date: string | null;
  tags: string[];
  repo: string | null;
  status: "published" | "draft";
  sourcePath: string; // path to processed mdx in .content_cache
};

export const contentIndex: ContentItem[] = ${JSON.stringify(items, null, 2)};
`;
  ensureDir(path.dirname(OUT_INDEX));
  fs.writeFileSync(OUT_INDEX, content, "utf8");
}

function main() {
  ensureDir(OUT_CACHE_DIR);
  ensureDir(OUT_DIAGRAMS_DIR);

  const allItems = [];

  for (const section of SECTIONS) {
    const sectionDir = path.join(CONTENT_DIR, section);
    if (!fs.existsSync(sectionDir)) continue;

    const files = readFilesRecursive(sectionDir).filter((p) => p.endsWith(".md") || p.endsWith(".mdx"));

    for (const filePath of files) {
      const raw = fs.readFileSync(filePath, "utf8");
      const parsed = matter(raw);
      const fm = normalizeFrontmatter(parsed.data ?? {}, filePath);

      if (fm.status !== "published" && fm.status !== "draft") {
        throw new Error(`Invalid status in ${filePath}. Use "published" or "draft".`);
      }

      const slug = slugFromPath(filePath);

      // Transform mermaid -> images
      const transformed = transformMermaidToImages({
        mdx: parsed.content,
        title: fm.title,
        description: fm.description
      });

      // Rebuild processed MDX with frontmatter stripped (we keep metadata in index)
      const processedMdx = transformed;

      const outDir = path.join(OUT_CACHE_DIR, section);
      ensureDir(outDir);

      const outPath = path.join(outDir, `${slug}.mdx`);
      fs.writeFileSync(outPath, processedMdx, "utf8");

      allItems.push({
        section,
        slug,
        title: fm.title,
        description: fm.description,
        date: fm.date ? String(fm.date) : null,
        tags: fm.tags.map(String),
        repo: fm.repo ? String(fm.repo) : null,
        status: fm.status,
        sourcePath: outPath
      });
    }
  }

  // stable sort: section then date desc then slug
  allItems.sort((a, b) => {
    if (a.section !== b.section) return a.section.localeCompare(b.section);
    const ad = a.date ? Date.parse(a.date) : 0;
    const bd = b.date ? Date.parse(b.date) : 0;
    if (ad !== bd) return bd - ad;
    return a.slug.localeCompare(b.slug);
  });

  writeIndex(allItems);

  console.log(`✅ Content built: ${allItems.length} items`);
  console.log(`✅ Diagrams in: public/diagrams`);
  console.log(`✅ Index: src/generated/contentIndex.ts`);
}

main();